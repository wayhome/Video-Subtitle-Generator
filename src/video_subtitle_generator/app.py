import streamlit as st
import torch
from transformers import pipeline, AutoModelForSpeechSeq2Seq, AutoProcessor
import os
import tempfile
from moviepy.editor import VideoFileClip
import srt
from datetime import timedelta
import re
from translator import Translator
from dotenv import load_dotenv
from pathlib import Path
import io
import logging
import sys
from typing import Union, List, Dict, Optional
import json
import hashlib

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="è§†é¢‘å­—å¹•ç”Ÿæˆå™¨",
    page_icon="ğŸ¬",
    layout="wide"
)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if 'video_paths' not in st.session_state:
    st.session_state.video_paths = set()

def on_file_change():
    """å½“æ–‡ä»¶è¢«é€‰æ‹©æ—¶çš„å›è°ƒå‡½æ•°"""
    if st.session_state.uploaded_files:
        for file in st.session_state.uploaded_files:
            # è·å–æ–‡ä»¶çš„æœ¬åœ°è·¯å¾„
            try:
                file_path = file.name
                if os.path.exists(file_path):
                    st.session_state.video_paths.add(file_path)
                else:
                    st.warning(f"æ— æ³•è®¿é—®æ–‡ä»¶: {file_path}")
            except Exception as e:
                st.error(f"å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")

# åˆå§‹åŒ–ç¿»è¯‘å™¨
@st.cache_resource
def load_translator():
    if not os.getenv("DEEPSEEK_API_KEY"):
        st.error("è¯·è®¾ç½® DEEPSEEK_API_KEY ç¯å¢ƒå˜é‡")
        st.stop()
    return Translator()

# åˆå§‹åŒ– Whisper æ¨¡å‹
@st.cache_resource
def load_whisper_model():
    """åŠ è½½ Whisper æ¨¡å‹"""
    model_id = os.getenv("WHISPER_MODEL_ID", "distil-whisper/distil-large-v2")
    
    # è®¾å¤‡é€‰æ‹©é€»è¾‘
    if torch.cuda.is_available():
        device = "cuda"
    elif torch.backends.mps.is_available():
        device = "mps"
    else:
        device = "cpu"
    
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºè¯­éŸ³è¯†åˆ«ç®¡é“
    pipe = pipeline(
        "automatic-speech-recognition",
        model=model_id,
        chunk_length_s=30,
        return_timestamps=True,  # ä½¿ç”¨å¥å­çº§åˆ«çš„æ—¶é—´æˆ³
        device=device
    )
    
    return pipe

def extract_audio(video_source, is_path=False):
    """ä»è§†é¢‘ä¸­æå–éŸ³é¢‘
    
    Args:
        video_source: è§†é¢‘æºï¼Œå¯ä»¥æ˜¯æ–‡ä»¶è·¯å¾„æˆ–ä¸Šä¼ çš„æ–‡ä»¶å¯¹è±¡
        is_path: æ˜¯å¦æ˜¯æ–‡ä»¶è·¯å¾„
    
    Returns:
        ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶çš„è·¯å¾„
    """
    with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_audio:
        if is_path:
            # ç›´æ¥ä»æœ¬åœ°æ–‡ä»¶æå–éŸ³é¢‘
            video = VideoFileClip(video_source)
        else:
            # ä»ä¸Šä¼ çš„æ–‡ä»¶æå–éŸ³é¢‘
            with tempfile.NamedTemporaryFile(suffix=f'.{video_source.name.split(".")[-1]}', delete=False) as temp_video:
                temp_video.write(video_source.getvalue())
                video = VideoFileClip(temp_video.name)
                # åˆ é™¤ä¸´æ—¶è§†é¢‘æ–‡ä»¶
                os.unlink(temp_video.name)
        
        # æå–å¹¶ä¿å­˜éŸ³é¢‘
        video.audio.write_audiofile(temp_audio.name)
        video.close()
        
        return temp_audio.name

def split_long_segment(segment: Dict, max_duration: float = 8.0, max_words: int = 20) -> List[Dict]:
    """å°†è¿‡é•¿çš„æ®µè½åˆ†å‰²æˆæ›´å°çš„ç‰‡æ®µ
    
    Args:
        segment: å­—å¹•æ®µè½
        max_duration: æœ€å¤§æ—¶é•¿ï¼ˆç§’ï¼‰
        max_words: æ¯æ®µæœ€å¤§å•è¯æ•°ï¼ˆè‹±æ–‡ï¼‰
    
    Returns:
        List[Dict]: åˆ†å‰²åçš„æ®µè½åˆ—è¡¨
    """
    text = segment["text"].strip()
    duration = segment["end"] - segment["start"]
    
    # è®¡ç®—å½“å‰æ–‡æœ¬çš„å•è¯æ•°
    word_count = len(re.findall(r'\b\w+\b', text))
    
    # å¦‚æœæ®µè½ä¸éœ€è¦åˆ†å‰²ï¼Œç›´æ¥è¿”å›
    if duration <= max_duration and word_count <= max_words:
        return [segment]
    
    # æŒ‰å¥å­åˆ†å‰²æ–‡æœ¬
    sentences = []
    
    # ä½¿ç”¨æ›´ç»†è‡´çš„åˆ†å‰²è§„åˆ™
    # é¦–å…ˆæŒ‰ä¸»è¦æ ‡ç‚¹åˆ†å‰²
    major_parts = re.split(r'([.!?ã€‚ï¼ï¼Ÿ]+)', text)
    
    # åˆå¹¶æ ‡ç‚¹ç¬¦å·ä¸å…¶å‰é¢çš„æ–‡æœ¬
    combined_parts = []
    i = 0
    while i < len(major_parts):
        if i + 1 < len(major_parts):
            # åˆå¹¶æ–‡æœ¬å’Œæ ‡ç‚¹
            combined_parts.append(major_parts[i] + major_parts[i+1])
            i += 2
        else:
            # å¤„ç†æœ€åä¸€ä¸ªéƒ¨åˆ†
            if major_parts[i].strip():
                combined_parts.append(major_parts[i])
            i += 1
    
    # å¦‚æœæ²¡æœ‰ä¸»è¦æ ‡ç‚¹ï¼Œæˆ–è€…åˆ†å‰²åè¿˜æ˜¯å¤ªé•¿ï¼Œè¿›ä¸€æ­¥å¤„ç†
    for part in combined_parts:
        part = part.strip()
        if not part:
            continue
            
        # è®¡ç®—å½“å‰éƒ¨åˆ†çš„å•è¯æ•°
        part_word_count = len(re.findall(r'\b\w+\b', part))
        
        # å¦‚æœå½“å‰éƒ¨åˆ†è¶…è¿‡æœ€å¤§å•è¯æ•°ï¼Œå°è¯•æŒ‰æ¬¡è¦æ ‡ç‚¹åˆ†å‰²
        if part_word_count > max_words:
            # æŒ‰é€—å·ã€åˆ†å·ç­‰æ¬¡è¦åˆ†éš”ç¬¦åˆ†å‰²
            minor_parts = re.split(r'([,;ï¼Œï¼›]+)', part)
            
            # åˆå¹¶æ¬¡è¦æ ‡ç‚¹ä¸å…¶å‰é¢çš„æ–‡æœ¬
            i = 0
            while i < len(minor_parts):
                if i + 1 < len(minor_parts):
                    # åˆå¹¶æ–‡æœ¬å’Œæ ‡ç‚¹
                    current = minor_parts[i] + minor_parts[i+1]
                    i += 2
                else:
                    # å¤„ç†æœ€åä¸€ä¸ªéƒ¨åˆ†
                    current = minor_parts[i]
                    i += 1
                
                current = current.strip()
                if not current:
                    continue
                
                # è®¡ç®—å½“å‰æ–‡æœ¬çš„å•è¯æ•°
                current_word_count = len(re.findall(r'\b\w+\b', current))
                
                # å¦‚æœåˆå¹¶åçš„æ–‡æœ¬ä»ç„¶å¤ªé•¿ï¼ŒæŒ‰å•è¯æ•°åˆ†å‰²
                if current_word_count > max_words:
                    words = current.split()
                    # æ¯ max_words/2 ä¸ªå•è¯ä¸ºä¸€ç»„
                    chunk_size = max(1, max_words // 2)
                    for j in range(0, len(words), chunk_size):
                        chunk = ' '.join(words[j:j+chunk_size])
                        if chunk:
                            sentences.append(chunk)
                else:
                    sentences.append(current)
        else:
            sentences.append(part)
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•åˆ†å‰²ç‚¹ï¼Œå¼ºåˆ¶æŒ‰å•è¯æ•°åˆ†å‰²
    if not sentences:
        words = text.split()
        # æ¯ max_words/2 ä¸ªå•è¯ä¸ºä¸€ç»„
        chunk_size = max(1, max_words // 2)
        for i in range(0, len(words), chunk_size):
            chunk = ' '.join(words[i:i+chunk_size])
            if chunk:
                sentences.append(chunk)
    
    # è®¡ç®—æ—¶é—´æˆ³
    result = []
    num_sentences = len(sentences)
    
    # è®¡ç®—æ¯ä¸ªå¥å­çš„æƒé‡ï¼ˆåŸºäºå•è¯æ•°ï¼‰
    weights = []
    total_words = 0
    for sentence in sentences:
        # è®¡ç®—æœ‰æ•ˆå•è¯æ•°ï¼ˆæ’é™¤æ ‡ç‚¹ç¬¦å·ï¼‰
        word_count = len(re.findall(r'\b\w+\b', sentence))
        weights.append(word_count)
        total_words += word_count
    
    # ç¡®ä¿æƒé‡ä¹‹å’Œä¸º1
    if total_words > 0:
        weights = [w/total_words for w in weights]
    else:
        # å¦‚æœæ²¡æœ‰æœ‰æ•ˆå•è¯ï¼Œå¹³å‡åˆ†é…
        weights = [1.0/num_sentences] * num_sentences
    
    # åˆ†é…æ—¶é—´æˆ³
    current_time = segment["start"]
    min_duration = 1.0  # æœ€å°æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
    
    for i, (sentence, weight) in enumerate(zip(sentences, weights)):
        # è®¡ç®—å½“å‰å¥å­çš„ç†æƒ³æŒç»­æ—¶é—´
        ideal_duration = duration * weight
        
        # ç¡®ä¿æœ€å°æŒç»­æ—¶é—´
        current_duration = max(ideal_duration, min_duration)
        
        # å¦‚æœæ˜¯æœ€åä¸€ä¸ªå¥å­ï¼Œä½¿ç”¨å‰©ä½™çš„æ‰€æœ‰æ—¶é—´
        if i == num_sentences - 1:
            end_time = segment["end"]
        else:
            # ç¡®ä¿ä¸ä¼šè¶…è¿‡æ€»æ—¶é•¿
            end_time = min(current_time + current_duration, segment["end"])
            # ä¸ºåç»­å¥å­é¢„ç•™è¶³å¤Ÿæ—¶é—´
            remaining_duration = segment["end"] - end_time
            remaining_sentences = num_sentences - i - 1
            if remaining_duration < remaining_sentences * min_duration:
                # å¦‚æœå‰©ä½™æ—¶é—´ä¸è¶³ï¼Œé€‚å½“ç¼©çŸ­å½“å‰å¥å­
                end_time = segment["end"] - (remaining_sentences * min_duration)
        
        result.append({
            "text": sentence,
            "start": current_time,
            "end": end_time
        })
        
        current_time = end_time
    
    return result

def remove_duplicates(text1: str, text2: str) -> str:
    """ç§»é™¤ä¸¤ä¸ªæ–‡æœ¬ä¹‹é—´çš„é‡å¤å†…å®¹
    
    Args:
        text1: å‰ä¸€æ®µæ–‡æœ¬
        text2: å½“å‰æ–‡æœ¬
    
    Returns:
        str: ç§»é™¤é‡å¤å†…å®¹åçš„æ–‡æœ¬
    """
    if not text1 or not text2:
        return text2
    
    words1 = text1.split()
    words2 = text2.split()
    
    # æŸ¥æ‰¾æœ€é•¿çš„é‡å¤åºåˆ—
    for i in range(len(words1), 0, -1):
        if ' '.join(words1[-i:]) == ' '.join(words2[:i]):
            return ' '.join(words2[i:])
    
    return text2

def create_srt_content(segments: List[Dict], translator: Translator) -> str:
    """åˆ›å»ºSRTæ ¼å¼çš„å­—å¹•å†…å®¹"""
    srt_segments = []
    merged_segments = []
    
    # ç¬¬ä¸€æ­¥ï¼šåˆå¹¶è¿‡çŸ­çš„ç‰‡æ®µ
    i = 0
    while i < len(segments):
        current = segments[i]
        text = current.get("text", "").strip()
        
        # å¦‚æœå½“å‰æ–‡æœ¬å¤ªçŸ­ä¸”ä¸æ˜¯æœ€åä¸€ä¸ªï¼Œå°è¯•ä¸ä¸‹ä¸€ä¸ªåˆå¹¶
        if len(text.split()) < 3 and i + 1 < len(segments):  # å‡å°‘åˆå¹¶é˜ˆå€¼
            next_seg = segments[i + 1]
            next_text = next_seg.get("text", "").strip()
            
            # åªæœ‰å½“åˆå¹¶åä¸ä¼šå¤ªé•¿æ—¶æ‰åˆå¹¶
            combined_text = f"{text} {next_text}"
            if len(combined_text) <= 50:  # æ§åˆ¶åˆå¹¶åçš„é•¿åº¦
                merged_segments.append({
                    "text": combined_text,
                    "start": current["start"],
                    "end": next_seg["end"]
                })
                i += 2
            else:
                merged_segments.append(current)
                i += 1
        else:
            merged_segments.append(current)
            i += 1
    
    # ç¬¬äºŒæ­¥ï¼šåˆ†å‰²è¿‡é•¿çš„ç‰‡æ®µ
    split_segments = []
    for segment in merged_segments:
        split_segments.extend(split_long_segment(segment))
    
    # åˆ›å»ºæœ¯è¯­æ˜ å°„è¡¨
    term_mapping = {
        "funding arbitrage": "èµ„é‡‘è´¹ç‡å¥—åˆ©",
        "perpetual": "æ°¸ç»­åˆçº¦",
        "spot": "ç°è´§",
        "beta neutral": "è´å¡”ä¸­æ€§",
        "dollar neutral": "ç¾å…ƒä¸­æ€§",
        "leverage": "æ æ†",
        "beta": "è´å¡”",
        "capital asset pricing model": "èµ„æœ¬èµ„äº§å®šä»·æ¨¡å‹",
        "regression model": "å›å½’æ¨¡å‹",
        "market index": "å¸‚åœºæŒ‡æ•°",
        "sensitivity": "æ•æ„Ÿåº¦",
    }
    
    # ç¬¬ä¸‰æ­¥ï¼šå¤„ç†å­—å¹•æ®µè½
    prev_text = ""
    for i, segment in enumerate(split_segments):
        try:
            # è·å–ä¸Šä¸‹æ–‡
            next_text = split_segments[i+1]["text"] if i < len(split_segments)-1 else None
            
            # å¤„ç†å½“å‰æ®µè½
            start_time = timedelta(seconds=segment["start"])
            end_time = timedelta(seconds=segment["end"])
            text = segment["text"]
            
            # ç§»é™¤é‡å¤å†…å®¹
            if prev_text:
                text = remove_duplicates(prev_text, text)
            
            # ä½¿ç”¨ä¸Šä¸‹æ–‡è¿›è¡Œæ·±åº¦çº é”™
            corrected_text = translator.review_english_with_context(text, prev_text, next_text)
            
            # åº”ç”¨æœ¯è¯­æ˜ å°„
            for eng, chn in term_mapping.items():
                corrected_text = corrected_text.replace(eng.lower(), eng)
            
            # ç¿»è¯‘æ–‡æœ¬
            chinese_text = translator.translate(corrected_text)
            
            # ç¡®ä¿æœ¯è¯­ä¸€è‡´æ€§
            for eng, chn in term_mapping.items():
                chinese_text = chinese_text.replace(eng, chn)
            
            # åˆ›å»ºå­—å¹•
            srt_segments.append(
                srt.Subtitle(index=len(srt_segments)+1,
                           start=start_time,
                           end=end_time,
                           content=f"{corrected_text}\n{chinese_text}")
            )
            
            # æ›´æ–°ä¸Šä¸‹æ–‡
            prev_text = text
            
        except Exception as e:
            logging.error(f"å¤„ç†å­—å¹•æ®µè½ {i+1} å¤±è´¥: {str(e)}")
            srt_segments.append(
                srt.Subtitle(index=len(srt_segments)+1,
                           start=start_time,
                           end=end_time,
                           content=f"{text}\n[ç¿»è¯‘å¤±è´¥]")
            )
    
    return srt.compose(srt_segments)

def get_cache_path(video_path: str) -> str:
    """è·å–ç¼“å­˜æ–‡ä»¶è·¯å¾„
    
    Args:
        video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        
    Returns:
        str: ç¼“å­˜æ–‡ä»¶è·¯å¾„
    """
    # ä½¿ç”¨è§†é¢‘æ–‡ä»¶çš„è·¯å¾„ç”Ÿæˆå”¯ä¸€çš„å“ˆå¸Œå€¼
    video_hash = hashlib.md5(str(video_path).encode()).hexdigest()
    cache_dir = Path("cache")
    cache_dir.mkdir(exist_ok=True)
    return str(cache_dir / f"{video_hash}.json")

def save_to_cache(cache_path: str, result: Dict) -> None:
    """ä¿å­˜è¯†åˆ«ç»“æœåˆ°ç¼“å­˜
    
    Args:
        cache_path: ç¼“å­˜æ–‡ä»¶è·¯å¾„
        result: è¯†åˆ«ç»“æœ
    """
    with open(cache_path, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)

def load_from_cache(cache_path: str) -> Optional[Dict]:
    """ä»ç¼“å­˜åŠ è½½è¯†åˆ«ç»“æœ
    
    Args:
        cache_path: ç¼“å­˜æ–‡ä»¶è·¯å¾„
        
    Returns:
        Dict: ç¼“å­˜çš„è¯†åˆ«ç»“æœï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å› None
    """
    try:
        if os.path.exists(cache_path):
            with open(cache_path, 'r', encoding='utf-8') as f:
                return json.load(f)
    except Exception as e:
        logging.warning(f"è¯»å–ç¼“å­˜å¤±è´¥: {str(e)}")
    return None

def process_video(video_source, pipe, translator, is_path=False):
    """å¤„ç†è§†é¢‘æ–‡ä»¶ï¼Œæ”¯æŒæ–‡ä»¶è·¯å¾„æˆ–ä¸Šä¼ çš„æ–‡ä»¶å¯¹è±¡"""
    try:
        # æ˜¾ç¤ºæ€»ä½“è¿›åº¦æ¡
        progress_placeholder = st.empty()
        progress_bar = progress_placeholder.progress(0)
        status_placeholder = st.empty()
        
        # è·å–ç¼“å­˜è·¯å¾„
        cache_path = get_cache_path(str(video_source) if is_path else video_source.name)
        
        # å°è¯•ä»ç¼“å­˜åŠ è½½
        cached_result = load_from_cache(cache_path)
        if cached_result:
            status_placeholder.info("âœ¨ ä½¿ç”¨ç¼“å­˜çš„è¯†åˆ«ç»“æœ")
            progress_bar.progress(20)
            raw_segments = []
            if isinstance(cached_result, dict):
                if "chunks" in cached_result:
                    # å¤„ç† chunks æ ¼å¼
                    total_chunks = len(cached_result["chunks"])
                    for i, chunk in enumerate(cached_result["chunks"]):
                        if isinstance(chunk, dict):
                            text = chunk.get("text", "").strip()
                            timestamp = chunk.get("timestamp", (0, 0))
                            raw_segments.append({
                                "text": text,
                                "start": timestamp[0],
                                "end": timestamp[1]
                            })
                        # æ›´æ–°è¿›åº¦
                        progress = 20 + (i + 1) / total_chunks * 10
                        progress_bar.progress(int(progress))
                        status_placeholder.info(f"ğŸ“ å¤„ç†ç¼“å­˜æ•°æ®: {i+1}/{total_chunks}")
                else:
                    # å¦‚æœæ²¡æœ‰ chunksï¼Œä½¿ç”¨å®Œæ•´æ–‡æœ¬
                    raw_segments = [{
                        "text": cached_result.get("text", "").strip(),
                        "start": 0,
                        "end": 0
                    }]
                    progress_bar.progress(30)
        else:
            # æå–éŸ³é¢‘
            status_placeholder.info("ğŸµ æå–éŸ³é¢‘ä¸­...")
            progress_bar.progress(10)
            audio_path = extract_audio(video_source, is_path)
            progress_bar.progress(20)
            
            # ç”Ÿæˆå­—å¹•
            status_placeholder.info("ğŸ¯ è¯†åˆ«è¯­éŸ³ä¸­...")
            result = pipe(audio_path)
            progress_bar.progress(30)
            
            # ä¿å­˜åˆ°ç¼“å­˜
            status_placeholder.info("ğŸ’¾ ä¿å­˜ç¼“å­˜...")
            save_to_cache(cache_path, result)
            
            # å¤„ç†ç»“æœä¸ºæ ‡å‡†æ ¼å¼
            raw_segments = []
            if isinstance(result, dict):
                if "chunks" in result:
                    # å¤„ç† chunks æ ¼å¼
                    total_chunks = len(result["chunks"])
                    for i, chunk in enumerate(result["chunks"]):
                        if isinstance(chunk, dict):
                            text = chunk.get("text", "").strip()
                            timestamp = chunk.get("timestamp", (0, 0))
                            raw_segments.append({
                                "text": text,
                                "start": timestamp[0],
                                "end": timestamp[1]
                            })
                        # æ›´æ–°è¿›åº¦
                        progress = 30 + (i + 1) / total_chunks * 10
                        progress_bar.progress(int(progress))
                        status_placeholder.info(f"ğŸ“ å¤„ç†éŸ³é¢‘æ®µè½: {i+1}/{total_chunks}")
                else:
                    # å¦‚æœæ²¡æœ‰ chunksï¼Œä½¿ç”¨å®Œæ•´æ–‡æœ¬
                    raw_segments = [{
                        "text": result.get("text", "").strip(),
                        "start": 0,
                        "end": 0
                    }]
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            os.unlink(audio_path)
        
        # åˆ†å‰²é•¿æ®µè½
        status_placeholder.info("âœ‚ï¸ åˆ†å‰²é•¿æ®µè½...")
        segments = []
        total_raw = len(raw_segments)
        for i, segment in enumerate(raw_segments):
            split_segs = split_long_segment(segment)
            segments.extend(split_segs)
            # æ›´æ–°è¿›åº¦
            progress = 40 + (i + 1) / total_raw * 20
            progress_bar.progress(int(progress))
            status_placeholder.info(f"âœ‚ï¸ åˆ†å‰²é•¿æ®µè½: {i+1}/{total_raw}")
        
        # åˆ›å»ºSRTå†…å®¹
        status_placeholder.info("ğŸŒ ç”ŸæˆåŒè¯­å­—å¹•ä¸­...")
        total_segments = len(segments)
        srt_segments = []
        
        # åˆ†æ‰¹å¤„ç†å­—å¹•æ®µè½ï¼Œæ¯æ‰¹æ˜¾ç¤ºè¿›åº¦
        for i, segment in enumerate(segments):
            try:
                # è·å–ä¸Šä¸‹æ–‡
                prev_text = segments[i-1]["text"] if i > 0 else None
                next_text = segments[i+1]["text"] if i < total_segments-1 else None
                
                # å¤„ç†å½“å‰æ®µè½
                start_time = timedelta(seconds=segment["start"])
                end_time = timedelta(seconds=segment["end"])
                text = segment["text"]
                
                # ç§»é™¤é‡å¤å†…å®¹
                if prev_text:
                    text = remove_duplicates(prev_text, text)
                
                # ä½¿ç”¨ä¸Šä¸‹æ–‡è¿›è¡Œæ·±åº¦çº é”™
                status_placeholder.info(f"ğŸ” æ­£åœ¨æ ¡å¯¹ç¬¬ {i+1}/{total_segments} æ®µå­—å¹•")
                corrected_text = translator.review_english_with_context(text, prev_text, next_text)
                
                # ç¿»è¯‘æ–‡æœ¬
                status_placeholder.info(f"ğŸŒ æ­£åœ¨ç¿»è¯‘ç¬¬ {i+1}/{total_segments} æ®µå­—å¹•")
                chinese_text = translator.translate(corrected_text)
                
                # åˆ›å»ºå­—å¹•
                srt_segments.append(
                    srt.Subtitle(index=len(srt_segments)+1,
                               start=start_time,
                               end=end_time,
                               content=f"{corrected_text}\n{chinese_text}")
                )
                
                # æ›´æ–°è¿›åº¦
                progress = 60 + (i + 1) / total_segments * 30
                progress_bar.progress(int(progress))
                
            except Exception as e:
                logging.error(f"å¤„ç†å­—å¹•æ®µè½ {i+1} å¤±è´¥: {str(e)}")
                srt_segments.append(
                    srt.Subtitle(index=len(srt_segments)+1,
                               start=start_time,
                               end=end_time,
                               content=f"{text}\n[ç¿»è¯‘å¤±è´¥]")
                )
        
        # åˆæˆæœ€ç»ˆçš„SRTå†…å®¹
        srt_content = srt.compose(srt_segments)
        
        # ä¿å­˜æˆ–ä¸‹è½½å­—å¹•æ–‡ä»¶
        status_placeholder.info("ğŸ’¾ ä¿å­˜å­—å¹•æ–‡ä»¶...")
        progress_bar.progress(95)
        
        if is_path:
            video_dir = os.path.dirname(video_source)
            video_name = Path(video_source).stem
            srt_path = os.path.join(video_dir, f"{video_name}.srt")
            with open(srt_path, 'w', encoding='utf-8') as f:
                f.write(srt_content)
            status_placeholder.success(f"âœ… å­—å¹•æ–‡ä»¶å·²ä¿å­˜åˆ°: {srt_path}")
        else:
            # å¦‚æœæ˜¯ä¸Šä¼ çš„æ–‡ä»¶ï¼Œæä¾›ä¸‹è½½æŒ‰é’®
            srt_filename = f"{Path(video_source.name).stem}.srt"
            st.download_button(
                label=f"ä¸‹è½½ {srt_filename}",
                data=srt_content.encode('utf-8'),
                file_name=srt_filename,
                mime='text/srt'
            )
            status_placeholder.success("âœ… å­—å¹•ç”Ÿæˆå®Œæˆï¼Œè¯·ç‚¹å‡»ä¸‹è½½æŒ‰é’®è·å–å­—å¹•æ–‡ä»¶")
        
        # å®Œæˆ
        progress_bar.progress(100)
        
    except Exception as e:
        name = video_source if isinstance(video_source, str) else video_source.name
        st.error(f"âŒ å¤„ç†æ–‡ä»¶ {name} æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        # æ‰“å°æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯ä»¥ä¾¿è°ƒè¯•
        import traceback
        st.error(traceback.format_exc())

def main():
    st.title("ğŸ¬ è§†é¢‘å­—å¹•ç”Ÿæˆå™¨")
    st.write("é€‰æ‹©è§†é¢‘æ–‡ä»¶æˆ–è¾“å…¥æœ¬åœ°æ–‡ä»¶è·¯å¾„ï¼Œè‡ªåŠ¨ç”Ÿæˆä¸­è‹±æ–‡åŒè¯­å­—å¹•")
    
    # APIå¯†é’¥è®¾ç½®ï¼ˆä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ç•Œé¢è¾“å…¥ï¼‰
    if not os.getenv("DEEPSEEK_API_KEY"):
        api_key = st.sidebar.text_input("DeepSeek API Key", type="password")
        if api_key:
            os.environ["DEEPSEEK_API_KEY"] = api_key
    
    # åŠ è½½æ¨¡å‹
    try:
        pipe = load_whisper_model()
        translator = load_translator()
    except Exception as e:
        st.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
        return

    # é€‰æ‹©è¾“å…¥æ–¹å¼
    input_method = st.radio(
        "é€‰æ‹©è¾“å…¥æ–¹å¼",
        ["ä¸Šä¼ æ–‡ä»¶", "æœ¬åœ°æ–‡ä»¶è·¯å¾„"]
    )
    
    if input_method == "ä¸Šä¼ æ–‡ä»¶":
        # æ–‡ä»¶ä¸Šä¼ 
        uploaded_files = st.file_uploader(
            "é€‰æ‹©è§†é¢‘æ–‡ä»¶ï¼ˆæ”¯æŒ MP4, MOV, AVI, MKVï¼‰",
            type=["mp4", "mov", "avi", "mkv"],
            accept_multiple_files=True
        )
        
        if uploaded_files:
            st.write(f"å·²ä¸Šä¼  {len(uploaded_files)} ä¸ªæ–‡ä»¶")
            if st.button("å¼€å§‹å¤„ç†"):
                for uploaded_file in uploaded_files:
                    st.write(f"å¤„ç†æ–‡ä»¶: {uploaded_file.name}")
                    process_video(uploaded_file, pipe, translator, is_path=False)
    
    else:
        # æœ¬åœ°æ–‡ä»¶è·¯å¾„è¾“å…¥
        local_paths = st.text_area(
            "è¾“å…¥æœ¬åœ°è§†é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆæ¯è¡Œä¸€ä¸ªè·¯å¾„ï¼‰",
            help="ä¾‹å¦‚ï¼š\n/path/to/video1.mp4\n/path/to/video2.mp4",
            height=100
        )
        
        if local_paths:
            paths = [path.strip() for path in local_paths.split('\n') if path.strip()]
            valid_paths = []
            
            # éªŒè¯æ–‡ä»¶
            for path in paths:
                if not os.path.exists(path):
                    st.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {path}")
                    continue
                if not path.lower().endswith(('.mp4', '.mov', '.avi', '.mkv')):
                    st.error(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {path}")
                    continue
                valid_paths.append(path)
            
            if valid_paths:
                st.write(f"æ‰¾åˆ° {len(valid_paths)} ä¸ªæœ‰æ•ˆæ–‡ä»¶")
                if st.button("å¼€å§‹å¤„ç†"):
                    for path in valid_paths:
                        st.write(f"å¤„ç†æ–‡ä»¶: {path}")
                        process_video(path, pipe, translator, is_path=True)

if __name__ == "__main__":
    main() 